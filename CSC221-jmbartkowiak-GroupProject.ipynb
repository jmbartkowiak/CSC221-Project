{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Jakub Bartkowiak\n",
    "### Colaborator: Deja Batiste \n",
    "#### Webscrape of https://en.wikipedia.org/wiki/Transistor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_html(url):\n",
    "    \"\"\"Fetch HTML content of the URL and handle HTTP errors.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "        #print(\"HTTP req successful\")\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP request failure. Statuss code: {response.status_code}. Error: {e}\")\n",
    "    return response.text\n",
    "\n",
    "# Configuration parameters\n",
    "site_url_stem = \"https://en.wikipedia.org/wiki/\"\n",
    "query = \"transistor count\"\n",
    "formatted_query = query.replace(\" \", \"_\")\n",
    "url = site_url_stem + formatted_query\n",
    "\n",
    "# Fetch HTML\n",
    "html = fetch_html(url)\n",
    "#print(f\"URL = {url}\")\n",
    "#print(\"HTML fetched successfully:\", html[:100])  # print a few characters to ensure output is as expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table found in the HTML\n",
      "Table parsed successfully: <table class=\"wikitable sortable\" style=\"text-align:left;\">\n",
      "<tbody><tr>\n",
      "<th width=\"300px\"><a href=\"/\n"
     ]
    }
   ],
   "source": [
    "def parse_table(html):\n",
    "    \"\"\"Parse HTML to find the table(s).\"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    if table:\n",
    "        print(\"Table found in the HTML\")\n",
    "    else:\n",
    "        print(\"No table found with that class, check the HTML\")\n",
    "    return table\n",
    "\n",
    "# Parse the HTML to find the table\n",
    "table = parse_table(html)\n",
    "print(\"Table parsed successfully:\", str(table)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed table data: ['Processor', 'Transistor count', 'Year', 'Designer', 'Process', 'Area ', 'Transistordensity', 'Processor', 'Transistor count', 'Year', 'Designer', 'Process', 'Area ', 'Transistordensity']\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean text extracted from HTML to remove references and make sure encoding is correct to prevent odd characters\"\"\"\n",
    "\n",
    "    #print(f\"text prior to numeric cleaning: {text}\")\n",
    "    text = unicodedata.normalize('NFKD', text)# normalize Unicode characters\n",
    "\n",
    "    text = re.sub(r'\\[.*?\\]', '', text) #remove anything in brackets, aka references\n",
    "    text = re.sub(r'\\xa0', ' ', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text) # Remove non-ASCII characters\n",
    "\n",
    "    text = text.strip()#strip to remove leading/trailing whitespac\n",
    "    text = text.encode('utf-8', 'ignore').decode('utf-8')# encode and decode to remove non-UTF8 characters\n",
    "    text = text.strip()\n",
    "\n",
    "    # Remove text within parentheses and commas, pluses before checking for numeric patterns\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    text = re.sub(r',|\\+', '', text)\n",
    "\n",
    "    if len(text) >= 3 and (text[0].isdigit() or text[0] == '.'): # Check if the first three characters are numeric or a period\n",
    "        match = re.search(r'^[\\d.]+', text)\n",
    "        if match:\n",
    "            text = match.group(0) # Get the complete numeric match\n",
    "        #print(f\"text after numeric cleaning: {text}\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_table(table):\n",
    "    \"\"\"Process table HTML to extract headers and rows\"\"\"\n",
    "    headers = [clean_text(th.get_text(strip=True)) for th in table.find_all('th')]\n",
    "    rows = []\n",
    "    for tr in table.find_all('tr'):\n",
    "        cols = [clean_text(td.get_text(strip=True)) for td in tr.find_all('td')]\n",
    "        if cols:\n",
    "            rows.append(cols)\n",
    "    #print(\"Table processing complete.\")\n",
    "    return [headers] + rows\n",
    "\n",
    "if table is not None:\n",
    "    table_data = process_table(table)\n",
    "    print(\"Processed table data:\", table_data[0])  # Print only the headers/possibly some data\n",
    "else:\n",
    "    print(\"No data to process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data save to CSV at c:\\Users\\JMBar\\Desktop\\SCHOOL - classes\\CSC-221\\Project\\CSC221-webscrape-data.csv\n"
     ]
    }
   ],
   "source": [
    "def save_to_csv(data, file_path):\n",
    "    #print(f\"File path: {file_path}\")\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "    print(f\"data save to CSV at {file_path}\")\n",
    "\n",
    "# Save the table data to CSV\n",
    "if table_data:\n",
    "    #output_path = os.path.join(os.getcwd(), f\"{formatted_query}.csv\")\n",
    "    output_path = os.path.join(os.getcwd(), f\"CSC221-webscrape-data.csv\")\n",
    "    save_to_csv(table_data, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
